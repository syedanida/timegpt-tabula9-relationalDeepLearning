{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7f1053b5de67499eb0b2c8aeb946ca79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f5700a8fd1d34a1d8c266956d21d8108",
              "IPY_MODEL_b88b305551d34a639f26db728a022a9f",
              "IPY_MODEL_969278665e41431f97ee2ba18dfc32f7"
            ],
            "layout": "IPY_MODEL_7f91bbb237e847a5a9a2c4a3dc7b21ea"
          }
        },
        "f5700a8fd1d34a1d8c266956d21d8108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a9a5248cd8d40ad86ac508d67ce0959",
            "placeholder": "​",
            "style": "IPY_MODEL_5836fe89bb5541e597a17a18de2a541a",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b88b305551d34a639f26db728a022a9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d86e83ed85c54bf3bb9136691bf2b290",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e8143cb3a2345b599e73c9f22530de5",
            "value": 7
          }
        },
        "969278665e41431f97ee2ba18dfc32f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c14b4fc1ac2432cb9bcee269a2a462b",
            "placeholder": "​",
            "style": "IPY_MODEL_83b9de2ff6ae479db5c991a7896920f2",
            "value": " 7/7 [00:12&lt;00:00,  1.73s/it]"
          }
        },
        "7f91bbb237e847a5a9a2c4a3dc7b21ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a9a5248cd8d40ad86ac508d67ce0959": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5836fe89bb5541e597a17a18de2a541a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d86e83ed85c54bf3bb9136691bf2b290": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e8143cb3a2345b599e73c9f22530de5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c14b4fc1ac2432cb9bcee269a2a462b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83b9de2ff6ae479db5c991a7896920f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fTZAGpPdmBf",
        "outputId": "8be26bd9-7995-425a-8ca9-0278f00bb5cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'rtfm' already exists and is not an empty directory.\n",
            "/content/rtfm\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/mlfoundations/rtfm.git\n",
        "%cd rtfm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install uv\n",
        "!uv pip install -r requirements.txt --system"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCTbm_8vgV-N",
        "outputId": "0611fa7e-7e44-4cee-ad4d-be1e865ddca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: uv in /usr/local/lib/python3.10/dist-packages (0.4.29)\n",
            "\u001b[2mUsing Python 3.10.12 environment at /usr\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m50 packages\u001b[0m \u001b[2min 91ms\u001b[0m\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!uv pip install git+https://github.com/jpgard/llama-recipes.git --system"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPkA8Sw6gnz5",
        "outputId": "5bc75758-f27d-4302-b4eb-3ed857b4f9e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.10.12 environment at /usr\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/jpgard/llama-recipes.git (\u001b[2mHEAD\u001b[0m)\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/jpgard/llama-recipes.git (\u001b[2mHEAD\u001b[0m)\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/jpgard/llama-recipes.git (\u001b[2mHEAD\u001b[0m)\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/jpgard/llama-recipes.git (\u001b[2mHEAD\u001b[0m)\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/jpgard/llama-recipes.git (\u001b[2mHEAD\u001b[0m)\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/jpgard/llama-recipes.git (\u001b[2mHEAD\u001b[0m)\n",
            "\u001b[2K\u001b[1A \u001b[32m\u001b[1mUpdated\u001b[0m\u001b[39m https://github.com/jpgard/llama-recipes.git (\u001b[2m186213f\u001b[0m)\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m122 packages\u001b[0m \u001b[2min 1.18s\u001b[0m\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m122 packages\u001b[0m \u001b[2min 0.24ms\u001b[0m\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!uv pip install -e . --system"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VemKoXENgrkO",
        "outputId": "c4e90c63-837b-4327-9a91-5b05fd74ea99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.10.12 environment at /usr\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 68ms\u001b[0m\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!uv pip install --no-deps git+https://github.com/mlfoundations/tableshift.git --system"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ev0pkpQVgv1U",
        "outputId": "a5aa124a-ec45-453e-c41b-f257dc088928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.10.12 environment at /usr\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/mlfoundations/tableshift.git (\u001b[2mHEAD\u001b[0m)\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/mlfoundations/tableshift.git (\u001b[2mHEAD\u001b[0m)\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/mlfoundations/tableshift.git (\u001b[2mHEAD\u001b[0m)\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/mlfoundations/tableshift.git (\u001b[2mHEAD\u001b[0m)\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/mlfoundations/tableshift.git (\u001b[2mHEAD\u001b[0m)\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/mlfoundations/tableshift.git (\u001b[2mHEAD\u001b[0m)\n",
            "\u001b[2K\u001b[1A \u001b[32m\u001b[1mUpdated\u001b[0m\u001b[39m https://github.com/mlfoundations/tableshift.git (\u001b[2mfca9429\u001b[0m)\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 882ms\u001b[0m\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 0.24ms\u001b[0m\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!uv pip install https://github.com/mlfoundations/tabliblib.git --system"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okV6SICShfbg",
        "outputId": "21bf38cf-4873-4988-91ec-e6af35c4b50a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.10.12 environment at /usr\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/mlfoundations/tabliblib.git (\u001b[2mHEAD\u001b[0m)\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/mlfoundations/tabliblib.git (\u001b[2mHEAD\u001b[0m)\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/mlfoundations/tabliblib.git (\u001b[2mHEAD\u001b[0m)\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/mlfoundations/tabliblib.git (\u001b[2mHEAD\u001b[0m)\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/mlfoundations/tabliblib.git (\u001b[2mHEAD\u001b[0m)\n",
            "\u001b[2K\u001b[1A\u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/mlfoundations/tabliblib.git (\u001b[2mHEAD\u001b[0m)\n",
            "\u001b[2K\u001b[1A \u001b[32m\u001b[1mUpdated\u001b[0m\u001b[39m https://github.com/mlfoundations/tabliblib.git (\u001b[2m95f5ae4\u001b[0m)\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 865ms\u001b[0m\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 0.20ms\u001b[0m\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnpkdrwXh5TL",
        "outputId": "7ff8310b-3a74-4f14-e51a-dff94a67c39a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, LlamaForCausalLM, AutoConfig\n",
        "\n",
        "from rtfm.configs import SerializerConfig, TrainConfig, TokenizerConfig\n",
        "from rtfm.inference_utils import InferenceModel\n",
        "from rtfm.serialization.serializers import get_serializer\n",
        "from rtfm.tokenization.text import prepare_tokenizer\n",
        "\n",
        "train_config = TrainConfig(model_name=\"mlfoundations/tabula-8b\", context_length=8192)\n",
        "\n",
        "tokenizer_config = TokenizerConfig()\n",
        "\n",
        "# Load the configuration\n",
        "config = AutoConfig.from_pretrained(train_config.model_name)\n",
        "\n",
        "# Set the torch_dtype to bfloat16 which matches TabuLa train/eval setup\n",
        "config.torch_dtype = 'bfloat16'\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(device)\n",
        "\n",
        "model = LlamaForCausalLM.from_pretrained(\n",
        "    train_config.model_name, device_map=\"cuda\", config=config).to(device)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(train_config.model_name)\n",
        "serializer = get_serializer(SerializerConfig())\n",
        "\n",
        "tokenizer, model = prepare_tokenizer(\n",
        "    model,\n",
        "    tokenizer=tokenizer,\n",
        "    pretrained_model_name_or_path=train_config.model_name,\n",
        "    model_max_length=train_config.context_length,\n",
        "    use_fast_tokenizer=tokenizer_config.use_fast_tokenizer,\n",
        "    serializer_tokens_embed_fn=tokenizer_config.serializer_tokens_embed_fn,\n",
        "    serializer_tokens=serializer.special_tokens\n",
        "    if tokenizer_config.add_serializer_tokens\n",
        "    else None,\n",
        ")\n",
        "\n",
        "inference_model = InferenceModel(model=model, tokenizer=tokenizer, serializer=serializer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330,
          "referenced_widgets": [
            "7f1053b5de67499eb0b2c8aeb946ca79",
            "f5700a8fd1d34a1d8c266956d21d8108",
            "b88b305551d34a639f26db728a022a9f",
            "969278665e41431f97ee2ba18dfc32f7",
            "7f91bbb237e847a5a9a2c4a3dc7b21ea",
            "4a9a5248cd8d40ad86ac508d67ce0959",
            "5836fe89bb5541e597a17a18de2a541a",
            "d86e83ed85c54bf3bb9136691bf2b290",
            "3e8143cb3a2345b599e73c9f22530de5",
            "1c14b4fc1ac2432cb9bcee269a2a462b",
            "83b9de2ff6ae479db5c991a7896920f2"
          ]
        },
        "id": "p0S79ZQig-sn",
        "outputId": "5eafd18b-9fd4-4481-a2eb-f1cc0fe46a09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "read user yaml files: 0it [00:00, ?it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/llama_recipes/model_checkpointing/checkpoint_handler.py:18: DeprecationWarning: `torch.distributed._shard.checkpoint` will be deprecated, use `torch.distributed.checkpoint` instead\n",
            "  from torch.distributed._shard.checkpoint import (\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f1053b5de67499eb0b2c8aeb946ca79"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "WARNING:root:adding special tokens {} to vocab\n",
            "WARNING:root:adding tokens {'eoc_token': '<|endcompletion|>', 'qa_sep_token': '<|endinput|>', 'ans_choices_sep_token': '||'} to vocab (as special tokens=True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def is_datetime_or_timedelta_dtype(ser):\n",
        "    return False\n",
        "pd.core.dtypes.common.is_datetime_or_timedelta_dtype = is_datetime_or_timedelta_dtype\n",
        "\n",
        "labeled_examples = pd.DataFrame(\n",
        "    [\n",
        "        {\"location\": \"New York\", \"temperature\": 22, \"humidity\": 65, \"wind_speed\": 12, \"pressure\": 1012, \"month\": \"July\",\n",
        "         \"weather_yesterday\": \"Sunny\", \"precipitation\": 0, \"visibility\": 10, \"weather_today\": \"Partly Sunny\"},\n",
        "        {\"location\": \"Los Angeles\", \"temperature\": 26, \"humidity\": 60, \"wind_speed\": 7, \"pressure\": 1015,\n",
        "         \"month\": \"July\", \"weather_yesterday\": \"Partly Sunny\", \"precipitation\": 0, \"visibility\": 10, \"weather_today\": \"Sunny\"},\n",
        "        {\"location\": \"Chicago\", \"temperature\": 18, \"humidity\": 70, \"wind_speed\": 15, \"pressure\": 1008, \"month\": \"July\",\n",
        "         \"weather_yesterday\": \"Partly Cloudy\", \"precipitation\": 0.1, \"visibility\": 8, \"weather_today\": \"Cloudy\"},\n",
        "        {\"location\": \"Houston\", \"temperature\": 30, \"humidity\": 80, \"wind_speed\": 10, \"pressure\": 1010, \"month\": \"July\",\n",
        "         \"weather_yesterday\": \"Rain\", \"precipitation\": 0.5, \"visibility\": 7, \"weather_today\": \"Rain\"},\n",
        "        {\"location\": \"Phoenix\", \"temperature\": 35, \"humidity\": 20, \"wind_speed\": 5, \"pressure\": 1005, \"month\": \"July\",\n",
        "         \"weather_yesterday\": \"Sunny\", \"precipitation\": 0, \"visibility\": 10, \"weather_today\": \"Sunny\"},\n",
        "        {\"location\": \"Philadelphia\", \"temperature\": 24, \"humidity\": 75, \"wind_speed\": 14, \"pressure\": 1009,\n",
        "         \"month\": \"July\", \"weather_yesterday\": \"Partly Cloudy\", \"precipitation\": 0.2, \"visibility\": 9,\n",
        "         \"weather_today\": \"Partly Cloudy\"},\n",
        "        {\"location\": \"San Antonio\", \"temperature\": 28, \"humidity\": 68, \"wind_speed\": 11, \"pressure\": 1011,\n",
        "         \"month\": \"July\", \"weather_yesterday\": \"Rain\", \"precipitation\": 0.4, \"visibility\": 8, \"weather_today\": \"Rain\"},\n",
        "        {\"location\": \"San Diego\", \"temperature\": 22, \"humidity\": 65, \"wind_speed\": 10, \"pressure\": 1014,\n",
        "         \"month\": \"July\", \"weather_yesterday\": \"Sunny\", \"precipitation\": 0, \"visibility\": 10, \"weather_today\": \"Partly Sunny\"},\n",
        "        {\"location\": \"Dallas\", \"temperature\": 27, \"humidity\": 72, \"wind_speed\": 9, \"pressure\": 1007, \"month\": \"July\",\n",
        "         \"weather_yesterday\": \"Partly Cloudy\", \"precipitation\": 0.3, \"visibility\": 9, \"weather_today\": \"Cloudy\"},\n",
        "    ]\n",
        ")\n",
        "target_example = pd.DataFrame(\n",
        "    [\n",
        "        {\"location\": \"San Jose\", \"temperature\": 23, \"humidity\": 55, \"wind_speed\": 8, \"pressure\": 1013, \"month\": \"July\",\n",
        "         \"weather_yesterday\": \"Sunny\", \"precipitation\": 0, \"visibility\": 10, \"weather_today\": \"Sunny\"},\n",
        "    ]\n",
        ")\n",
        "\n",
        "inference_model = InferenceModel(model=model, tokenizer=tokenizer, serializer=serializer)\n",
        "\n",
        "output = inference_model.predict(\n",
        "    target_example=target_example,\n",
        "    target_colname=\"weather_today\",\n",
        "    target_choices=[\"Sunny\", \"Partly Sunny\", \"Cloudy\", \"Partly Cloudy\", \"Rain\"],\n",
        "    labeled_examples=labeled_examples,\n",
        ")\n",
        "print(f\"Prediction for sample \\n {target_example} \\n is: {output}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKsyykquqIHF",
        "outputId": "e904eda9-777c-41e6-b4e5-1c9878cd5079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for sample \n",
            "    location  temperature  humidity  wind_speed  pressure month  \\\n",
            "0  San Jose           23        55           8      1013  July   \n",
            "\n",
            "  weather_yesterday  precipitation  visibility weather_today  \n",
            "0             Sunny              0          10         Sunny   \n",
            " is: Sunny\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "target_example = pd.DataFrame(\n",
        "    [\n",
        "        {\"location\": \"San Jose\", \"temperature\": 27, \"humidity\": 45, \"wind_speed\": 3, \"pressure\": 1007, \"month\": \"July\",\n",
        "         \"weather_yesterday\": \"Partly Cloudy\", \"precipitation\": 0, \"visibility\": 7}, #, \"weather_today\": \"Sunny\"},\n",
        "    ]\n",
        ")\n",
        "\n",
        "inference_model = InferenceModel(model=model, tokenizer=tokenizer, serializer=serializer)\n",
        "\n",
        "output = inference_model.predict(\n",
        "    target_example=target_example,\n",
        "    target_colname=\"weather_today\",\n",
        "    target_choices=[\"Sunny\", \"Partly Sunny\", \"Cloudy\", \"Partly Cloudy\", \"Rain\"],\n",
        "    # labeled_examples=labeled_examples,\n",
        ")\n",
        "print(f\"Prediction for sample \\n {target_example} \\n is: {output}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWA8_1JOzuor",
        "outputId": "d9c2ade2-a630-4607-80e9-1bf9787a7d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Column weather_today is not in target example; got columns Index(['location', 'temperature', 'humidity', 'wind_speed', 'pressure',\n",
            "       'month', 'weather_yesterday', 'precipitation', 'visibility'],\n",
            "      dtype='object'). Adding a dummy placeholder with empty values for preprocessing. This behavior is expected if your target samples do not contain the target column at all.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for sample \n",
            "    location  temperature  humidity  wind_speed  pressure month  \\\n",
            "0  San Jose           27        45           3      1007  July   \n",
            "\n",
            "  weather_yesterday  precipitation  visibility  weather_today  \n",
            "0     Partly Cloudy              0           7            NaN   \n",
            " is: Partly Sunny\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rtfm.serialization.serialization_utils import discretize_continuous_column\n",
        "\n",
        "examples = pd.DataFrame(\n",
        "    [\n",
        "    {\"location\": \"New York\", \"size_sqft\": 1200, \"bedrooms\": 3, \"bathrooms\": 2, \"age\": 10, \"lot_size_acres\": 0.15, \"garage\": True, \"price\": 850},\n",
        "    {\"location\": \"Los Angeles\", \"size_sqft\": 1500, \"bedrooms\": 4, \"bathrooms\": 3, \"age\": 8, \"lot_size_acres\": 0.25, \"garage\": True, \"price\": 950},\n",
        "    {\"location\": \"Chicago\", \"size_sqft\": 1300, \"bedrooms\": 3, \"bathrooms\": 2, \"age\": 15, \"lot_size_acres\": 0.2, \"garage\": False, \"price\": 700},\n",
        "    {\"location\": \"Houston\", \"size_sqft\": 1700, \"bedrooms\": 4, \"bathrooms\": 3, \"age\": 5, \"lot_size_acres\": 0.3, \"garage\": True, \"price\": 650},\n",
        "    {\"location\": \"Phoenix\", \"size_sqft\": 1600, \"bedrooms\": 3, \"bathrooms\": 2, \"age\": 7, \"lot_size_acres\": 0.25, \"garage\": True, \"price\": 750},\n",
        "    {\"location\": \"Philadelphia\", \"size_sqft\": 1400, \"bedrooms\": 3, \"bathrooms\": 2, \"age\": 12, \"lot_size_acres\": 0.18, \"garage\": False, \"price\": 600},\n",
        "    {\"location\": \"San Antonio\", \"size_sqft\": 1800, \"bedrooms\": 4, \"bathrooms\": 3, \"age\": 3, \"lot_size_acres\": 0.4, \"garage\": True, \"price\": 700},\n",
        "    {\"location\": \"San Diego\", \"size_sqft\": 1550, \"bedrooms\": 3, \"bathrooms\": 2, \"age\": 9, \"lot_size_acres\": 0.22, \"garage\": True, \"price\": 850},\n",
        "    {\"location\": \"Dallas\", \"size_sqft\": 1450, \"bedrooms\": 3, \"bathrooms\": 2, \"age\": 11, \"lot_size_acres\": 0.19, \"garage\": True, \"price\": 700},\n",
        "    {\"location\": \"San Jose\", \"size_sqft\": 1600, \"bedrooms\": 4, \"bathrooms\": 3, \"age\": 6, \"lot_size_acres\": 0.2, \"garage\": False, \"price\": 800},\n",
        "    {\"location\": \"Seattle\", \"size_sqft\": 1800, \"bedrooms\": 4, \"bathrooms\": 2, \"age\": 10, \"lot_size_acres\": 0.2, \"garage\": False, \"price\": 925},\n",
        "]\n",
        ")\n",
        "\n",
        "examples[\"price\"] = discretize_continuous_column(examples[\"price\"], num_buckets=4)\n",
        "target_choices = examples[\"price\"].unique().tolist()\n",
        "\n",
        "target_example = examples.iloc[[0]]\n",
        "labeled_examples = examples.iloc[1:]\n",
        "\n",
        "inference_model = InferenceModel(model=model, tokenizer=tokenizer, serializer=serializer)\n",
        "\n",
        "output = inference_model.predict(\n",
        "    target_example=target_example,\n",
        "    target_colname=\"price\",\n",
        "    target_choices=target_choices,\n",
        "    labeled_examples=labeled_examples,\n",
        ")\n",
        "print(f\"Prediction for sample \\n {target_example} \\n is: {output}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRqfPjLHqMso",
        "outputId": "c73504a9-0bbe-4551-ada8-302b5ae286dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/rtfm/rtfm/datasets/data_utils.py:131: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(columns=columns_to_drop, inplace=True)\n",
            "/content/rtfm/rtfm/datasets/data_utils.py:131: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.drop(columns=columns_to_drop, inplace=True)\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for sample \n",
            "    location  size_sqft  bedrooms  bathrooms  age  lot_size_acres  garage  \\\n",
            "0  New York       1200         3          2   10            0.15    True   \n",
            "\n",
            "                price  \n",
            "0  greater than 850.0   \n",
            " is: between 750.0 and 850.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "target_example = pd.DataFrame(\n",
        "    [\n",
        "    {\"location\": \"New York\", \"size_sqft\": 1200, \"bedrooms\": 3, \"bathrooms\": 2, \"age\": 10, \"lot_size_acres\": 0.15, \"garage\": True}, #, \"price\": 850},\n",
        "]\n",
        ")\n",
        "\n",
        "inference_model = InferenceModel(model=model, tokenizer=tokenizer, serializer=serializer)\n",
        "\n",
        "output = inference_model.predict(\n",
        "    target_example=target_example,\n",
        "    target_colname=\"price\",\n",
        "    target_choices=target_choices,\n",
        ")\n",
        "print(f\"Prediction for sample \\n {target_example} \\n is: {output}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BYjpK71z0Rz",
        "outputId": "a17a2b13-33f3-46ca-eff2-433d6469fcf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Column price is not in target example; got columns Index(['location', 'size_sqft', 'bedrooms', 'bathrooms', 'age',\n",
            "       'lot_size_acres', 'garage'],\n",
            "      dtype='object'). Adding a dummy placeholder with empty values for preprocessing. This behavior is expected if your target samples do not contain the target column at all.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for sample \n",
            "    location  size_sqft  bedrooms  bathrooms  age  lot_size_acres  garage  \\\n",
            "0  New York       1200         3          2   10            0.15    True   \n",
            "\n",
            "   price  \n",
            "0    NaN   \n",
            " is: greater than 850.0\n"
          ]
        }
      ]
    }
  ]
}